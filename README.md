# Introduction
It is an application of computer vision, object detection in various key positions of the hand to detect and track the position and gesture of the hand. This is the same way that Face Mesh works or a program used to detect and track faces.
# Project Prerequisites:
You need to install the dlib library and face_recognition API from PyPI:
- pip install opencv-python
- pip install mediapipe
# Application
Hand Tracking is used to track location. and understand gestures which can be applied to create programs that accept user input by doing hand gestures Such as swiping hands, making ok symbols, pressing likes, pressing dislike to connect to the next command.

# Preliminary work
Hand Tracking starts with detecting the palm with the Palm Detection Model and then identifies 21 key hand positions through a program called Hand Landmark Model that simulates hand gestures from the incoming image detection.

# Requirements :
Jupyter Notebook
# Importing the Libraries :
- mediapipe as mp
- cv2


# CONCLUSION
This deep learning project teaches you how to develop a human face recognition project with python libraries dlib and face_recognition APIs (of OpenCV).

It also covers the introduction to face_recognition API. We have implemented this python project in two parts:

In the first part, we have seen how to store the information about human face structure, i.e face embedding. Then we learn how to store these embeddings.
In the second part, we have seen how to recognize the person by comparing the new face embeddings with the stored one.





