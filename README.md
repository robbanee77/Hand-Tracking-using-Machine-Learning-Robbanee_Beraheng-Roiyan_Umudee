# Introduction
It is an application of computer vision, object detection in various key positions of the hand to detect and track the position and gesture of the hand. This is the same way that Face Mesh works or a program used to detect and track faces.
# Project Prerequisites:
You need to install the dlib library and face_recognition API from PyPI:
- pip install opencv-python
- pip install mediapipe

# Preliminary work
Hand Tracking starts with detecting the palm with the Palm Detection Model and then identifies 21 key hand positions through a program called Hand Landmark Model that simulates hand gestures from the incoming image detection.

# Step to do
- download tool
- import tools
- Identify the camera
- get data from camera
- video display
- Hand data and hand detection commands
- convert color system
- hand detection in the figure
- hand position
- hand detection in video
- show results
- Specify the location of a landmark
- Landmark location display via webcam

# Requirements :
Jupyter Notebook
# Importing the Libraries :
- mediapipe as mp
- cv2


# CONCLUSION
Hand Tracking is used to track location. and understand gestures which can be applied to create programs that accept user input by doing hand gestures Such as swiping hands, making ok symbols, pressing likes, pressing dislike to connect to the next command.






